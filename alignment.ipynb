{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 3)\n",
      "[[  0.8455726   -0.10514125  23.62203827]\n",
      " [  0.10514125   0.8455726  -12.57776428]]\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "\n",
    "\n",
    "image=cv2.imread('p3.jpeg')\n",
    "print image.shape\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "detections = detector(image, 1) #Detect the faces in the image\n",
    "k=9\n",
    "p1=[]\n",
    "p2=[]\n",
    "face=[]\n",
    "for k,d in enumerate(detections): #For each detected face\n",
    "\n",
    " shape = predictor(image, d)\n",
    " a=(shape.part(36).x,shape.part(36).y)\n",
    " b=(shape.part(45).x,shape.part(45).y)\n",
    " p1=[a,b]\n",
    " \n",
    "point=[(shape.part(20).y,shape.part(25).y),(1,1)]\n",
    "\n",
    "p2=[((int(0.3*200),66)),(int(0.7*200),66)]\n",
    "s60 = math.sin(60*math.pi/180);\n",
    "c60 = math.cos(60*math.pi/180);  \n",
    "inPts = np.copy(p1).tolist();\n",
    "outPts = np.copy(p2).tolist();\n",
    "xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0];\n",
    "yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1];\n",
    "inPts.append([np.int(xin), np.int(yin)]);\n",
    "xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0];\n",
    "yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1];\n",
    "outPts.append([np.int(xout), np.int(yout)]);\n",
    "tform = cv2.estimateRigidTransform(np.array([inPts]), np.array([outPts]), False);\n",
    "img2 = cv2.warpAffine(image, tform, (200,200));   \n",
    "print tform\n",
    "\n",
    "'''\n",
    "point=np.array(point)\n",
    "\n",
    "\n",
    "point_trans = np.reshape(point, (2,1,2));\n",
    "\n",
    "making code time effective then uncomment it and change if condition \n",
    "\n",
    "\n",
    "\n",
    "point_trans = cv2.transform(face, tform);\n",
    "point_trans = np.int64(np.reshape(point_trans, (2, 2)))\n",
    "print point_trans\n",
    "'''\n",
    "detections = detector(img2, 1)\n",
    "for k,d in enumerate(detections): #For each detected face\n",
    " face=[[d.left(),d.right()],[d.top(),d.bottom()]]\n",
    " \n",
    " \n",
    "if shape.part(20).y>shape.part(25).y:\n",
    "        top=shape.part(20).y\n",
    "else :\n",
    "    top=shape.part(25).y\n",
    "\n",
    "print top\n",
    "img2_cropped=img2[top:face[1][1],face[0][0]:face[0][1]]\n",
    "img2_cropped=cv2.resize(img2_cropped,(200,200))\n",
    "\n",
    "\n",
    "\n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow('img')\n",
    "cv2.imshow('img', np.hstack([image,img2_cropped]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
